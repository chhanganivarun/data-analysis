{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test data paths will be available as env variables during evaluation\n",
    "TRAIN_DATA_PATH = os.getenv(\"TRAIN_DATA_PATH\")\n",
    "TEST_DATA_PATH = os.getenv(\"TEST_DATA_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test data paths will be available as env variables during evaluation\n",
    "TRAIN_DATA_PATH = './143e2751-7e99-4d17-bb9b-f0faec66e4b9_train.csv'\n",
    "TEST_DATA_PATH = './83f63b01-14ae-450d-98cb-328e9467162f_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "X_train, y_train = train_data.iloc[:,:-1], train_data.iloc[:,-1]\n",
    "\n",
    "# Train the model\n",
    "classifier = SVC(gamma='auto')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "submission = classifier.predict(test_data)\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "# Export the prediction as submission.csv\n",
    "submission.to_csv('submission.csv', header=['class'], index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att16</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>att22</th>\n",
       "      <th>att23</th>\n",
       "      <th>att24</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   att1  att2  att3  att4  att5  att6  att7  att8  att9  att10  ...  att16  \\\n",
       "0     1     1     1     1     1     0     1     1     0      1  ...      1   \n",
       "1     1     1     1     1     1     1     1     1     0      1  ...      1   \n",
       "2     0     1     1     0     0     1     0     1     1      1  ...      1   \n",
       "3     1     1     0     1     1     1     1     0     1      1  ...      0   \n",
       "4     1     1     1     0     1     1     1     1     0      1  ...      0   \n",
       "\n",
       "   att17  att18  att19  att20  att21  att22  att23  att24  class  \n",
       "0      1      1      1      0      0      1      1      0      8  \n",
       "1      0      0      0      1      1      1      0      0      9  \n",
       "2      0      0      1      1      1      1      0      1      7  \n",
       "3      0      0      0      0      1      1      1      1      6  \n",
       "4      1      0      0      0      1      1      1      1      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att15</th>\n",
       "      <th>att16</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>att22</th>\n",
       "      <th>att23</th>\n",
       "      <th>att24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   att1  att2  att3  att4  att5  att6  att7  att8  att9  att10  ...  att15  \\\n",
       "0     0     0     1     0     0     1     0     1     1      1  ...      0   \n",
       "1     1     1     1     1     1     1     1     1     0      1  ...      0   \n",
       "2     0     1     1     0     1     1     1     1     0      0  ...      1   \n",
       "3     0     0     0     0     0     1     0     0     0      0  ...      0   \n",
       "4     1     0     1     1     1     1     1     1     1      1  ...      1   \n",
       "\n",
       "   att16  att17  att18  att19  att20  att21  att22  att23  att24  \n",
       "0      0      0      0      0      1      0      1      0      0  \n",
       "1      1      1      0      0      1      1      0      0      1  \n",
       "2      0      0      0      0      0      1      1      0      0  \n",
       "3      0      0      1      1      1      1      0      0      0  \n",
       "4      1      1      1      1      0      0      0      0      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_train,y_train,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76       221\n",
      "           1       0.78      0.79      0.78       247\n",
      "           2       0.80      0.85      0.82       220\n",
      "           3       0.64      0.62      0.63       200\n",
      "           4       0.75      0.79      0.77       204\n",
      "           5       0.80      0.75      0.77       244\n",
      "           6       0.80      0.71      0.76       223\n",
      "           7       0.76      0.73      0.75       248\n",
      "           8       0.62      0.62      0.62       213\n",
      "           9       0.64      0.60      0.62       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(gamma='auto')\n",
    "classifier.fit(train_X, train_y)\n",
    "\n",
    "preds_y = classifier.predict(val_X)\n",
    "\n",
    "print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.72       221\n",
      "           1       0.75      0.71      0.73       247\n",
      "           2       0.66      0.79      0.72       220\n",
      "           3       0.57      0.62      0.59       200\n",
      "           4       0.76      0.68      0.72       204\n",
      "           5       0.73      0.76      0.75       244\n",
      "           6       0.73      0.73      0.73       223\n",
      "           7       0.67      0.59      0.63       248\n",
      "           8       0.64      0.65      0.64       213\n",
      "           9       0.57      0.64      0.60       230\n",
      "\n",
      "    accuracy                           0.68      2250\n",
      "   macro avg       0.69      0.68      0.68      2250\n",
      "weighted avg       0.69      0.68      0.68      2250\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.72       221\n",
      "           1       0.79      0.71      0.75       247\n",
      "           2       0.94      0.73      0.82       220\n",
      "           3       0.55      0.77      0.64       200\n",
      "           4       0.68      0.75      0.71       204\n",
      "           5       0.80      0.68      0.74       244\n",
      "           6       0.73      0.73      0.73       223\n",
      "           7       0.65      0.70      0.68       248\n",
      "           8       0.64      0.65      0.64       213\n",
      "           9       0.57      0.64      0.60       230\n",
      "\n",
      "    accuracy                           0.70      2250\n",
      "   macro avg       0.72      0.70      0.70      2250\n",
      "weighted avg       0.72      0.70      0.70      2250\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       221\n",
      "           1       0.78      0.78      0.78       247\n",
      "           2       0.88      0.81      0.85       220\n",
      "           3       0.52      0.82      0.64       200\n",
      "           4       0.76      0.79      0.77       204\n",
      "           5       0.79      0.75      0.77       244\n",
      "           6       0.73      0.73      0.73       223\n",
      "           7       0.82      0.68      0.74       248\n",
      "           8       0.72      0.58      0.64       213\n",
      "           9       0.63      0.63      0.63       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.74      0.73      0.73      2250\n",
      "weighted avg       0.74      0.73      0.73      2250\n",
      "\n",
      "35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       221\n",
      "           1       0.78      0.78      0.78       247\n",
      "           2       0.87      0.82      0.84       220\n",
      "           3       0.59      0.76      0.66       200\n",
      "           4       0.76      0.79      0.77       204\n",
      "           5       0.79      0.75      0.77       244\n",
      "           6       0.74      0.78      0.76       223\n",
      "           7       0.83      0.67      0.74       248\n",
      "           8       0.61      0.62      0.62       213\n",
      "           9       0.63      0.63      0.63       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.74      0.73      0.73      2250\n",
      "weighted avg       0.74      0.73      0.73      2250\n",
      "\n",
      "40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       221\n",
      "           1       0.78      0.79      0.78       247\n",
      "           2       0.87      0.82      0.84       220\n",
      "           3       0.59      0.75      0.66       200\n",
      "           4       0.76      0.79      0.78       204\n",
      "           5       0.78      0.76      0.77       244\n",
      "           6       0.74      0.78      0.76       223\n",
      "           7       0.83      0.67      0.74       248\n",
      "           8       0.61      0.62      0.62       213\n",
      "           9       0.63      0.63      0.63       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.74      0.73      0.73      2250\n",
      "weighted avg       0.74      0.73      0.73      2250\n",
      "\n",
      "50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       221\n",
      "           1       0.78      0.81      0.79       247\n",
      "           2       0.79      0.85      0.82       220\n",
      "           3       0.61      0.63      0.62       200\n",
      "           4       0.78      0.77      0.78       204\n",
      "           5       0.78      0.76      0.77       244\n",
      "           6       0.74      0.78      0.76       223\n",
      "           7       0.81      0.72      0.76       248\n",
      "           8       0.61      0.62      0.62       213\n",
      "           9       0.64      0.59      0.61       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n",
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       221\n",
      "           1       0.78      0.79      0.78       247\n",
      "           2       0.77      0.87      0.81       220\n",
      "           3       0.60      0.64      0.62       200\n",
      "           4       0.78      0.79      0.79       204\n",
      "           5       0.78      0.77      0.77       244\n",
      "           6       0.78      0.75      0.76       223\n",
      "           7       0.81      0.72      0.76       248\n",
      "           8       0.67      0.60      0.63       213\n",
      "           9       0.63      0.60      0.62       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n",
      "200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       221\n",
      "           1       0.76      0.80      0.78       247\n",
      "           2       0.80      0.80      0.80       220\n",
      "           3       0.61      0.66      0.63       200\n",
      "           4       0.79      0.75      0.77       204\n",
      "           5       0.74      0.77      0.75       244\n",
      "           6       0.77      0.71      0.74       223\n",
      "           7       0.78      0.70      0.74       248\n",
      "           8       0.63      0.62      0.63       213\n",
      "           9       0.60      0.58      0.59       230\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.72      0.72      0.72      2250\n",
      "weighted avg       0.72      0.72      0.72      2250\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       221\n",
      "           1       0.76      0.80      0.78       247\n",
      "           2       0.83      0.80      0.81       220\n",
      "           3       0.57      0.67      0.61       200\n",
      "           4       0.78      0.75      0.77       204\n",
      "           5       0.72      0.75      0.73       244\n",
      "           6       0.74      0.65      0.69       223\n",
      "           7       0.79      0.71      0.74       248\n",
      "           8       0.64      0.63      0.63       213\n",
      "           9       0.57      0.58      0.58       230\n",
      "\n",
      "    accuracy                           0.71      2250\n",
      "   macro avg       0.71      0.71      0.71      2250\n",
      "weighted avg       0.71      0.71      0.71      2250\n",
      "\n",
      "400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       221\n",
      "           1       0.75      0.77      0.76       247\n",
      "           2       0.79      0.78      0.79       220\n",
      "           3       0.56      0.64      0.59       200\n",
      "           4       0.78      0.76      0.77       204\n",
      "           5       0.68      0.77      0.73       244\n",
      "           6       0.75      0.67      0.71       223\n",
      "           7       0.77      0.69      0.73       248\n",
      "           8       0.62      0.63      0.62       213\n",
      "           9       0.58      0.52      0.55       230\n",
      "\n",
      "    accuracy                           0.70      2250\n",
      "   macro avg       0.70      0.70      0.70      2250\n",
      "weighted avg       0.70      0.70      0.70      2250\n",
      "\n",
      "500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       221\n",
      "           1       0.76      0.77      0.76       247\n",
      "           2       0.81      0.79      0.80       220\n",
      "           3       0.56      0.64      0.60       200\n",
      "           4       0.78      0.75      0.76       204\n",
      "           5       0.68      0.77      0.72       244\n",
      "           6       0.74      0.65      0.70       223\n",
      "           7       0.76      0.70      0.73       248\n",
      "           8       0.60      0.59      0.60       213\n",
      "           9       0.55      0.53      0.54       230\n",
      "\n",
      "    accuracy                           0.70      2250\n",
      "   macro avg       0.70      0.69      0.69      2250\n",
      "weighted avg       0.70      0.70      0.70      2250\n",
      "\n",
      "600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       221\n",
      "           1       0.76      0.72      0.74       247\n",
      "           2       0.80      0.79      0.80       220\n",
      "           3       0.57      0.64      0.60       200\n",
      "           4       0.76      0.75      0.76       204\n",
      "           5       0.68      0.76      0.72       244\n",
      "           6       0.72      0.65      0.68       223\n",
      "           7       0.72      0.71      0.72       248\n",
      "           8       0.60      0.60      0.60       213\n",
      "           9       0.55      0.53      0.54       230\n",
      "\n",
      "    accuracy                           0.69      2250\n",
      "   macro avg       0.69      0.69      0.69      2250\n",
      "weighted avg       0.69      0.69      0.69      2250\n",
      "\n",
      "700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71       221\n",
      "           1       0.76      0.73      0.74       247\n",
      "           2       0.80      0.80      0.80       220\n",
      "           3       0.56      0.63      0.59       200\n",
      "           4       0.76      0.74      0.75       204\n",
      "           5       0.65      0.74      0.69       244\n",
      "           6       0.73      0.63      0.68       223\n",
      "           7       0.72      0.69      0.70       248\n",
      "           8       0.60      0.56      0.58       213\n",
      "           9       0.53      0.51      0.52       230\n",
      "\n",
      "    accuracy                           0.68      2250\n",
      "   macro avg       0.68      0.68      0.68      2250\n",
      "weighted avg       0.68      0.68      0.68      2250\n",
      "\n",
      "800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71       221\n",
      "           1       0.77      0.73      0.75       247\n",
      "           2       0.77      0.78      0.78       220\n",
      "           3       0.54      0.59      0.57       200\n",
      "           4       0.75      0.73      0.74       204\n",
      "           5       0.64      0.71      0.67       244\n",
      "           6       0.69      0.65      0.67       223\n",
      "           7       0.74      0.70      0.72       248\n",
      "           8       0.59      0.54      0.56       213\n",
      "           9       0.52      0.51      0.52       230\n",
      "\n",
      "    accuracy                           0.67      2250\n",
      "   macro avg       0.67      0.67      0.67      2250\n",
      "weighted avg       0.67      0.67      0.67      2250\n",
      "\n",
      "900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       221\n",
      "           1       0.76      0.72      0.74       247\n",
      "           2       0.80      0.79      0.80       220\n",
      "           3       0.55      0.62      0.59       200\n",
      "           4       0.73      0.73      0.73       204\n",
      "           5       0.67      0.70      0.69       244\n",
      "           6       0.71      0.68      0.69       223\n",
      "           7       0.73      0.71      0.72       248\n",
      "           8       0.58      0.55      0.56       213\n",
      "           9       0.50      0.51      0.51       230\n",
      "\n",
      "    accuracy                           0.67      2250\n",
      "   macro avg       0.67      0.67      0.67      2250\n",
      "weighted avg       0.67      0.67      0.67      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_nodes in [10,20,30,35,40,50,100,200,300,400,500,600,700,800,900]:\n",
    "    classifier = DecisionTreeClassifier(max_leaf_nodes=num_nodes)\n",
    "    classifier.fit(train_X, train_y)\n",
    "\n",
    "    preds_y = classifier.predict(val_X)\n",
    "    print(num_nodes)\n",
    "    print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       221\n",
      "           1       0.00      0.00      0.00       247\n",
      "           2       0.26      0.80      0.39       220\n",
      "           3       0.00      0.00      0.00       200\n",
      "           4       0.37      0.75      0.49       204\n",
      "           5       0.00      0.00      0.00       244\n",
      "           6       0.23      0.75      0.36       223\n",
      "           7       0.00      0.00      0.00       248\n",
      "           8       0.00      0.00      0.00       213\n",
      "           9       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.22      2250\n",
      "   macro avg       0.09      0.23      0.12      2250\n",
      "weighted avg       0.08      0.22      0.12      2250\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       221\n",
      "           1       0.01      0.01      0.01       247\n",
      "           2       0.40      0.73      0.51       220\n",
      "           3       0.16      0.11      0.13       200\n",
      "           4       0.42      0.75      0.54       204\n",
      "           5       0.45      0.71      0.55       244\n",
      "           6       0.35      0.67      0.46       223\n",
      "           7       0.00      0.00      0.00       248\n",
      "           8       0.00      0.00      0.00       213\n",
      "           9       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.29      2250\n",
      "   macro avg       0.18      0.30      0.22      2250\n",
      "weighted avg       0.18      0.29      0.22      2250\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       221\n",
      "           1       0.01      0.01      0.01       247\n",
      "           2       0.38      0.73      0.50       220\n",
      "           3       0.18      0.12      0.14       200\n",
      "           4       0.38      0.72      0.50       204\n",
      "           5       0.48      0.65      0.55       244\n",
      "           6       0.33      0.68      0.45       223\n",
      "           7       0.00      0.00      0.00       248\n",
      "           8       0.10      0.08      0.09       213\n",
      "           9       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.29      2250\n",
      "   macro avg       0.19      0.30      0.22      2250\n",
      "weighted avg       0.18      0.29      0.22      2250\n",
      "\n",
      "35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       221\n",
      "           1       0.01      0.01      0.01       247\n",
      "           2       0.37      0.73      0.49       220\n",
      "           3       0.23      0.12      0.15       200\n",
      "           4       0.35      0.72      0.47       204\n",
      "           5       0.50      0.65      0.57       244\n",
      "           6       0.33      0.68      0.45       223\n",
      "           7       0.00      0.00      0.00       248\n",
      "           8       0.10      0.08      0.09       213\n",
      "           9       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.29      2250\n",
      "   macro avg       0.19      0.30      0.22      2250\n",
      "weighted avg       0.19      0.29      0.22      2250\n",
      "\n",
      "40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       221\n",
      "           1       0.01      0.01      0.01       247\n",
      "           2       0.36      0.73      0.49       220\n",
      "           3       0.23      0.12      0.15       200\n",
      "           4       0.36      0.72      0.48       204\n",
      "           5       0.52      0.65      0.58       244\n",
      "           6       0.32      0.68      0.44       223\n",
      "           7       0.00      0.00      0.00       248\n",
      "           8       0.10      0.08      0.09       213\n",
      "           9       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.29      2250\n",
      "   macro avg       0.19      0.30      0.22      2250\n",
      "weighted avg       0.19      0.29      0.22      2250\n",
      "\n",
      "50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       221\n",
      "           1       0.01      0.01      0.01       247\n",
      "           2       0.37      0.73      0.49       220\n",
      "           3       0.24      0.12      0.16       200\n",
      "           4       0.35      0.72      0.47       204\n",
      "           5       0.52      0.66      0.58       244\n",
      "           6       0.33      0.67      0.44       223\n",
      "           7       0.01      0.01      0.01       248\n",
      "           8       0.10      0.08      0.09       213\n",
      "           9       0.75      0.03      0.05       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.27      0.30      0.23      2250\n",
      "weighted avg       0.27      0.30      0.23      2250\n",
      "\n",
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.06      0.11       221\n",
      "           1       0.00      0.00      0.00       247\n",
      "           2       0.36      0.74      0.49       220\n",
      "           3       0.29      0.15      0.20       200\n",
      "           4       0.36      0.72      0.48       204\n",
      "           5       0.61      0.66      0.63       244\n",
      "           6       0.34      0.70      0.46       223\n",
      "           7       0.04      0.03      0.03       248\n",
      "           8       0.10      0.09      0.09       213\n",
      "           9       0.73      0.03      0.07       230\n",
      "\n",
      "    accuracy                           0.31      2250\n",
      "   macro avg       0.34      0.32      0.26      2250\n",
      "weighted avg       0.34      0.31      0.25      2250\n",
      "\n",
      "200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.21      0.31       221\n",
      "           1       0.01      0.00      0.01       247\n",
      "           2       0.36      0.77      0.49       220\n",
      "           3       0.50      0.34      0.41       200\n",
      "           4       0.45      0.72      0.56       204\n",
      "           5       0.52      0.66      0.58       244\n",
      "           6       0.35      0.66      0.46       223\n",
      "           7       0.10      0.05      0.07       248\n",
      "           8       0.22      0.28      0.25       213\n",
      "           9       0.41      0.04      0.07       230\n",
      "\n",
      "    accuracy                           0.36      2250\n",
      "   macro avg       0.36      0.37      0.32      2250\n",
      "weighted avg       0.35      0.36      0.31      2250\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.27      0.37       221\n",
      "           1       0.02      0.01      0.01       247\n",
      "           2       0.36      0.77      0.49       220\n",
      "           3       0.48      0.29      0.36       200\n",
      "           4       0.45      0.75      0.56       204\n",
      "           5       0.62      0.66      0.64       244\n",
      "           6       0.40      0.68      0.51       223\n",
      "           7       0.32      0.20      0.25       248\n",
      "           8       0.27      0.34      0.30       213\n",
      "           9       0.41      0.08      0.14       230\n",
      "\n",
      "    accuracy                           0.40      2250\n",
      "   macro avg       0.39      0.40      0.36      2250\n",
      "weighted avg       0.39      0.40      0.36      2250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/LE-Course/Sem2/SMAI/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/varun/LE-Course/Sem2/SMAI/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/varun/LE-Course/Sem2/SMAI/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/varun/LE-Course/Sem2/SMAI/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/varun/LE-Course/Sem2/SMAI/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/varun/LE-Course/Sem2/SMAI/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.37       221\n",
      "           1       0.27      0.18      0.22       247\n",
      "           2       0.40      0.76      0.52       220\n",
      "           3       0.49      0.32      0.38       200\n",
      "           4       0.49      0.73      0.58       204\n",
      "           5       0.62      0.67      0.65       244\n",
      "           6       0.54      0.65      0.59       223\n",
      "           7       0.55      0.54      0.54       248\n",
      "           8       0.29      0.39      0.34       213\n",
      "           9       0.45      0.10      0.17       230\n",
      "\n",
      "    accuracy                           0.46      2250\n",
      "   macro avg       0.46      0.46      0.44      2250\n",
      "weighted avg       0.46      0.46      0.44      2250\n",
      "\n",
      "500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.56       221\n",
      "           1       0.55      0.26      0.36       247\n",
      "           2       0.43      0.79      0.56       220\n",
      "           3       0.50      0.37      0.43       200\n",
      "           4       0.53      0.73      0.61       204\n",
      "           5       0.64      0.35      0.45       244\n",
      "           6       0.41      0.72      0.52       223\n",
      "           7       0.52      0.46      0.49       248\n",
      "           8       0.30      0.42      0.35       213\n",
      "           9       0.44      0.13      0.20       230\n",
      "\n",
      "    accuracy                           0.47      2250\n",
      "   macro avg       0.49      0.47      0.45      2250\n",
      "weighted avg       0.49      0.47      0.45      2250\n",
      "\n",
      "600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.56       221\n",
      "           1       0.49      0.34      0.40       247\n",
      "           2       0.48      0.77      0.59       220\n",
      "           3       0.46      0.37      0.41       200\n",
      "           4       0.52      0.73      0.61       204\n",
      "           5       0.66      0.34      0.45       244\n",
      "           6       0.44      0.72      0.54       223\n",
      "           7       0.54      0.51      0.52       248\n",
      "           8       0.35      0.41      0.38       213\n",
      "           9       0.53      0.27      0.35       230\n",
      "\n",
      "    accuracy                           0.49      2250\n",
      "   macro avg       0.51      0.50      0.48      2250\n",
      "weighted avg       0.51      0.49      0.48      2250\n",
      "\n",
      "700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       221\n",
      "           1       0.57      0.37      0.45       247\n",
      "           2       0.50      0.76      0.60       220\n",
      "           3       0.45      0.36      0.40       200\n",
      "           4       0.53      0.74      0.62       204\n",
      "           5       0.71      0.55      0.62       244\n",
      "           6       0.50      0.69      0.58       223\n",
      "           7       0.56      0.54      0.55       248\n",
      "           8       0.36      0.44      0.40       213\n",
      "           9       0.53      0.28      0.37       230\n",
      "\n",
      "    accuracy                           0.53      2250\n",
      "   macro avg       0.54      0.53      0.52      2250\n",
      "weighted avg       0.54      0.53      0.52      2250\n",
      "\n",
      "800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       221\n",
      "           1       0.65      0.40      0.49       247\n",
      "           2       0.50      0.75      0.60       220\n",
      "           3       0.46      0.37      0.41       200\n",
      "           4       0.51      0.73      0.60       204\n",
      "           5       0.68      0.61      0.65       244\n",
      "           6       0.68      0.67      0.67       223\n",
      "           7       0.52      0.61      0.56       248\n",
      "           8       0.42      0.39      0.41       213\n",
      "           9       0.53      0.35      0.42       230\n",
      "\n",
      "    accuracy                           0.55      2250\n",
      "   macro avg       0.56      0.55      0.55      2250\n",
      "weighted avg       0.56      0.55      0.55      2250\n",
      "\n",
      "900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63       221\n",
      "           1       0.66      0.63      0.64       247\n",
      "           2       0.70      0.77      0.73       220\n",
      "           3       0.46      0.36      0.41       200\n",
      "           4       0.53      0.77      0.63       204\n",
      "           5       0.72      0.61      0.66       244\n",
      "           6       0.67      0.66      0.67       223\n",
      "           7       0.57      0.59      0.58       248\n",
      "           8       0.43      0.51      0.47       213\n",
      "           9       0.56      0.39      0.46       230\n",
      "\n",
      "    accuracy                           0.59      2250\n",
      "   macro avg       0.59      0.59      0.59      2250\n",
      "weighted avg       0.60      0.59      0.59      2250\n",
      "\n",
      "1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66       221\n",
      "           1       0.69      0.63      0.66       247\n",
      "           2       0.71      0.77      0.74       220\n",
      "           3       0.55      0.59      0.57       200\n",
      "           4       0.65      0.80      0.72       204\n",
      "           5       0.74      0.60      0.66       244\n",
      "           6       0.66      0.68      0.67       223\n",
      "           7       0.56      0.59      0.57       248\n",
      "           8       0.45      0.46      0.46       213\n",
      "           9       0.49      0.41      0.45       230\n",
      "\n",
      "    accuracy                           0.62      2250\n",
      "   macro avg       0.62      0.62      0.62      2250\n",
      "weighted avg       0.62      0.62      0.62      2250\n",
      "\n",
      "1500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62       221\n",
      "           1       0.69      0.65      0.67       247\n",
      "           2       0.74      0.80      0.77       220\n",
      "           3       0.52      0.54      0.53       200\n",
      "           4       0.68      0.75      0.71       204\n",
      "           5       0.64      0.56      0.60       244\n",
      "           6       0.61      0.59      0.60       223\n",
      "           7       0.60      0.58      0.59       248\n",
      "           8       0.40      0.39      0.40       213\n",
      "           9       0.40      0.42      0.41       230\n",
      "\n",
      "    accuracy                           0.59      2250\n",
      "   macro avg       0.59      0.59      0.59      2250\n",
      "weighted avg       0.59      0.59      0.59      2250\n",
      "\n",
      "2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       221\n",
      "           1       0.64      0.65      0.65       247\n",
      "           2       0.74      0.73      0.73       220\n",
      "           3       0.50      0.56      0.52       200\n",
      "           4       0.66      0.69      0.67       204\n",
      "           5       0.55      0.52      0.53       244\n",
      "           6       0.54      0.50      0.52       223\n",
      "           7       0.61      0.58      0.60       248\n",
      "           8       0.46      0.45      0.45       213\n",
      "           9       0.40      0.41      0.41       230\n",
      "\n",
      "    accuracy                           0.58      2250\n",
      "   macro avg       0.58      0.58      0.58      2250\n",
      "weighted avg       0.58      0.58      0.58      2250\n",
      "\n",
      "5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.64       221\n",
      "           1       0.65      0.67      0.66       247\n",
      "           2       0.75      0.73      0.74       220\n",
      "           3       0.50      0.54      0.52       200\n",
      "           4       0.67      0.70      0.68       204\n",
      "           5       0.54      0.51      0.52       244\n",
      "           6       0.53      0.51      0.52       223\n",
      "           7       0.61      0.57      0.59       248\n",
      "           8       0.47      0.42      0.44       213\n",
      "           9       0.38      0.40      0.39       230\n",
      "\n",
      "    accuracy                           0.57      2250\n",
      "   macro avg       0.57      0.57      0.57      2250\n",
      "weighted avg       0.57      0.57      0.57      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_nodes in [10,20,30,35,40,50,100,200,300,400,500,600,700,800,900,1000,1500,2000,5000]:\n",
    "    classifier = DecisionTreeRegressor(max_leaf_nodes=num_nodes)\n",
    "    classifier.fit(train_X, train_y)\n",
    "\n",
    "    preds_y = np.around(classifier.predict(val_X))\n",
    "    print(num_nodes)\n",
    "    print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75       221\n",
      "           1       0.78      0.81      0.80       247\n",
      "           2       0.80      0.80      0.80       220\n",
      "           3       0.59      0.67      0.63       200\n",
      "           4       0.80      0.81      0.80       204\n",
      "           5       0.76      0.76      0.76       244\n",
      "           6       0.76      0.73      0.74       223\n",
      "           7       0.78      0.72      0.75       248\n",
      "           8       0.66      0.63      0.64       213\n",
      "           9       0.65      0.60      0.62       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_X, train_y)\n",
    "\n",
    "preds_y = classifier.predict(val_X)\n",
    "print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       221\n",
      "           1       0.77      0.79      0.78       247\n",
      "           2       0.77      0.86      0.81       220\n",
      "           3       0.55      0.65      0.59       200\n",
      "           4       0.71      0.81      0.76       204\n",
      "           5       0.72      0.69      0.71       244\n",
      "           6       0.69      0.65      0.67       223\n",
      "           7       0.77      0.69      0.73       248\n",
      "           8       0.63      0.54      0.58       213\n",
      "           9       0.65      0.50      0.57       230\n",
      "\n",
      "    accuracy                           0.70      2250\n",
      "   macro avg       0.69      0.69      0.69      2250\n",
      "weighted avg       0.70      0.70      0.69      2250\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       221\n",
      "           1       0.78      0.81      0.79       247\n",
      "           2       0.77      0.84      0.80       220\n",
      "           3       0.63      0.68      0.65       200\n",
      "           4       0.76      0.79      0.78       204\n",
      "           5       0.76      0.75      0.75       244\n",
      "           6       0.76      0.68      0.72       223\n",
      "           7       0.78      0.74      0.76       248\n",
      "           8       0.65      0.59      0.62       213\n",
      "           9       0.63      0.57      0.60       230\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.72      0.72      0.72      2250\n",
      "weighted avg       0.72      0.72      0.72      2250\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72       221\n",
      "           1       0.79      0.78      0.79       247\n",
      "           2       0.81      0.81      0.81       220\n",
      "           3       0.59      0.67      0.63       200\n",
      "           4       0.76      0.82      0.79       204\n",
      "           5       0.75      0.76      0.75       244\n",
      "           6       0.75      0.72      0.74       223\n",
      "           7       0.78      0.72      0.75       248\n",
      "           8       0.65      0.59      0.62       213\n",
      "           9       0.64      0.57      0.60       230\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.72      0.72      0.72      2250\n",
      "weighted avg       0.72      0.72      0.72      2250\n",
      "\n",
      "50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74       221\n",
      "           1       0.79      0.80      0.79       247\n",
      "           2       0.81      0.84      0.83       220\n",
      "           3       0.59      0.67      0.63       200\n",
      "           4       0.75      0.79      0.77       204\n",
      "           5       0.76      0.76      0.76       244\n",
      "           6       0.75      0.70      0.73       223\n",
      "           7       0.78      0.73      0.75       248\n",
      "           8       0.68      0.62      0.65       213\n",
      "           9       0.64      0.60      0.62       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n",
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75       221\n",
      "           1       0.77      0.79      0.78       247\n",
      "           2       0.80      0.81      0.80       220\n",
      "           3       0.61      0.66      0.63       200\n",
      "           4       0.79      0.82      0.80       204\n",
      "           5       0.77      0.76      0.76       244\n",
      "           6       0.77      0.74      0.75       223\n",
      "           7       0.79      0.74      0.76       248\n",
      "           8       0.66      0.62      0.64       213\n",
      "           9       0.65      0.62      0.63       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n",
      "150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       221\n",
      "           1       0.79      0.81      0.80       247\n",
      "           2       0.83      0.82      0.82       220\n",
      "           3       0.59      0.67      0.62       200\n",
      "           4       0.80      0.82      0.81       204\n",
      "           5       0.77      0.77      0.77       244\n",
      "           6       0.74      0.72      0.73       223\n",
      "           7       0.79      0.72      0.75       248\n",
      "           8       0.67      0.64      0.65       213\n",
      "           9       0.66      0.61      0.64       230\n",
      "\n",
      "    accuracy                           0.74      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.74      0.74      0.74      2250\n",
      "\n",
      "200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       221\n",
      "           1       0.80      0.79      0.80       247\n",
      "           2       0.85      0.83      0.84       220\n",
      "           3       0.61      0.67      0.64       200\n",
      "           4       0.79      0.81      0.80       204\n",
      "           5       0.78      0.78      0.78       244\n",
      "           6       0.75      0.73      0.74       223\n",
      "           7       0.79      0.73      0.76       248\n",
      "           8       0.67      0.65      0.66       213\n",
      "           9       0.64      0.64      0.64       230\n",
      "\n",
      "    accuracy                           0.74      2250\n",
      "   macro avg       0.74      0.74      0.74      2250\n",
      "weighted avg       0.74      0.74      0.74      2250\n",
      "\n",
      "250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74       221\n",
      "           1       0.79      0.80      0.80       247\n",
      "           2       0.82      0.81      0.82       220\n",
      "           3       0.59      0.65      0.62       200\n",
      "           4       0.79      0.80      0.80       204\n",
      "           5       0.76      0.76      0.76       244\n",
      "           6       0.75      0.73      0.74       223\n",
      "           7       0.79      0.72      0.75       248\n",
      "           8       0.65      0.64      0.65       213\n",
      "           9       0.65      0.62      0.64       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       221\n",
      "           1       0.79      0.81      0.80       247\n",
      "           2       0.80      0.82      0.81       220\n",
      "           3       0.62      0.66      0.63       200\n",
      "           4       0.80      0.82      0.81       204\n",
      "           5       0.76      0.76      0.76       244\n",
      "           6       0.75      0.73      0.74       223\n",
      "           7       0.78      0.73      0.75       248\n",
      "           8       0.66      0.63      0.65       213\n",
      "           9       0.63      0.62      0.63       230\n",
      "\n",
      "    accuracy                           0.73      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.73      0.73      0.73      2250\n",
      "\n",
      "400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75       221\n",
      "           1       0.80      0.81      0.80       247\n",
      "           2       0.81      0.80      0.81       220\n",
      "           3       0.62      0.66      0.63       200\n",
      "           4       0.79      0.82      0.81       204\n",
      "           5       0.76      0.77      0.76       244\n",
      "           6       0.75      0.73      0.74       223\n",
      "           7       0.79      0.74      0.76       248\n",
      "           8       0.65      0.62      0.64       213\n",
      "           9       0.64      0.62      0.63       230\n",
      "\n",
      "    accuracy                           0.74      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.74      0.74      0.73      2250\n",
      "\n",
      "500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       221\n",
      "           1       0.80      0.80      0.80       247\n",
      "           2       0.81      0.81      0.81       220\n",
      "           3       0.60      0.66      0.63       200\n",
      "           4       0.78      0.83      0.80       204\n",
      "           5       0.77      0.77      0.77       244\n",
      "           6       0.74      0.72      0.73       223\n",
      "           7       0.78      0.75      0.76       248\n",
      "           8       0.66      0.63      0.65       213\n",
      "           9       0.65      0.62      0.64       230\n",
      "\n",
      "    accuracy                           0.74      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.74      0.74      0.73      2250\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       221\n",
      "           1       0.80      0.80      0.80       247\n",
      "           2       0.82      0.81      0.82       220\n",
      "           3       0.60      0.64      0.62       200\n",
      "           4       0.79      0.83      0.81       204\n",
      "           5       0.77      0.77      0.77       244\n",
      "           6       0.76      0.73      0.74       223\n",
      "           7       0.79      0.74      0.76       248\n",
      "           8       0.66      0.63      0.65       213\n",
      "           9       0.64      0.61      0.62       230\n",
      "\n",
      "    accuracy                           0.74      2250\n",
      "   macro avg       0.73      0.73      0.73      2250\n",
      "weighted avg       0.74      0.74      0.73      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_est in [10,20,30,50,100,150,200,250,300,400,500,600]:\n",
    "    classifier = RandomForestClassifier(n_estimators=num_est)\n",
    "    classifier.fit(train_X, train_y)\n",
    "\n",
    "    preds_y = classifier.predict(val_X)\n",
    "    print(num_est)\n",
    "    print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.11      0.20       221\n",
      "           1       0.34      0.17      0.22       247\n",
      "           2       0.42      0.67      0.52       220\n",
      "           3       0.21      0.23      0.22       200\n",
      "           4       0.32      0.58      0.41       204\n",
      "           5       0.33      0.42      0.37       244\n",
      "           6       0.28      0.57      0.38       223\n",
      "           7       0.24      0.23      0.23       248\n",
      "           8       0.32      0.22      0.26       213\n",
      "           9       0.47      0.03      0.06       230\n",
      "\n",
      "    accuracy                           0.32      2250\n",
      "   macro avg       0.37      0.32      0.29      2250\n",
      "weighted avg       0.37      0.32      0.29      2250\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.14      0.25       221\n",
      "           1       0.40      0.23      0.30       247\n",
      "           2       0.44      0.68      0.54       220\n",
      "           3       0.20      0.20      0.20       200\n",
      "           4       0.38      0.65      0.48       204\n",
      "           5       0.31      0.42      0.35       244\n",
      "           6       0.27      0.55      0.36       223\n",
      "           7       0.23      0.23      0.23       248\n",
      "           8       0.29      0.19      0.23       213\n",
      "           9       1.00      0.03      0.06       230\n",
      "\n",
      "    accuracy                           0.33      2250\n",
      "   macro avg       0.43      0.33      0.30      2250\n",
      "weighted avg       0.43      0.33      0.30      2250\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.09      0.16       221\n",
      "           1       0.25      0.13      0.17       247\n",
      "           2       0.42      0.71      0.53       220\n",
      "           3       0.18      0.18      0.18       200\n",
      "           4       0.37      0.61      0.46       204\n",
      "           5       0.31      0.39      0.35       244\n",
      "           6       0.28      0.59      0.38       223\n",
      "           7       0.18      0.20      0.19       248\n",
      "           8       0.30      0.18      0.22       213\n",
      "           9       0.70      0.03      0.06       230\n",
      "\n",
      "    accuracy                           0.31      2250\n",
      "   macro avg       0.38      0.31      0.27      2250\n",
      "weighted avg       0.38      0.31      0.27      2250\n",
      "\n",
      "50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.10      0.17       221\n",
      "           1       0.26      0.14      0.18       247\n",
      "           2       0.42      0.68      0.52       220\n",
      "           3       0.18      0.17      0.18       200\n",
      "           4       0.33      0.58      0.42       204\n",
      "           5       0.30      0.40      0.34       244\n",
      "           6       0.28      0.58      0.38       223\n",
      "           7       0.21      0.21      0.21       248\n",
      "           8       0.25      0.15      0.19       213\n",
      "           9       0.88      0.03      0.06       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.40      0.31      0.27      2250\n",
      "weighted avg       0.40      0.30      0.26      2250\n",
      "\n",
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.12       221\n",
      "           1       0.26      0.14      0.18       247\n",
      "           2       0.40      0.70      0.51       220\n",
      "           3       0.21      0.20      0.20       200\n",
      "           4       0.37      0.63      0.46       204\n",
      "           5       0.33      0.43      0.38       244\n",
      "           6       0.26      0.58      0.36       223\n",
      "           7       0.16      0.17      0.16       248\n",
      "           8       0.23      0.13      0.17       213\n",
      "           9       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.32      0.30      0.25      2250\n",
      "weighted avg       0.32      0.30      0.25      2250\n",
      "\n",
      "150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.06      0.12       221\n",
      "           1       0.27      0.14      0.19       247\n",
      "           2       0.41      0.70      0.52       220\n",
      "           3       0.21      0.20      0.21       200\n",
      "           4       0.38      0.62      0.47       204\n",
      "           5       0.33      0.43      0.37       244\n",
      "           6       0.28      0.61      0.38       223\n",
      "           7       0.18      0.19      0.18       248\n",
      "           8       0.22      0.12      0.15       213\n",
      "           9       0.62      0.02      0.04       230\n",
      "\n",
      "    accuracy                           0.31      2250\n",
      "   macro avg       0.36      0.31      0.26      2250\n",
      "weighted avg       0.36      0.31      0.26      2250\n",
      "\n",
      "200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.06      0.11       221\n",
      "           1       0.24      0.13      0.16       247\n",
      "           2       0.42      0.71      0.52       220\n",
      "           3       0.17      0.17      0.17       200\n",
      "           4       0.38      0.62      0.47       204\n",
      "           5       0.31      0.41      0.35       244\n",
      "           6       0.27      0.60      0.37       223\n",
      "           7       0.19      0.21      0.20       248\n",
      "           8       0.24      0.12      0.16       213\n",
      "           9       0.50      0.02      0.04       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.35      0.30      0.26      2250\n",
      "weighted avg       0.35      0.30      0.25      2250\n",
      "\n",
      "250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.05      0.09       221\n",
      "           1       0.24      0.13      0.17       247\n",
      "           2       0.41      0.70      0.52       220\n",
      "           3       0.19      0.19      0.19       200\n",
      "           4       0.38      0.63      0.47       204\n",
      "           5       0.32      0.41      0.36       244\n",
      "           6       0.28      0.61      0.38       223\n",
      "           7       0.18      0.19      0.18       248\n",
      "           8       0.20      0.11      0.14       213\n",
      "           9       0.50      0.01      0.03       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.34      0.30      0.25      2250\n",
      "weighted avg       0.34      0.30      0.25      2250\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.06      0.11       221\n",
      "           1       0.22      0.12      0.16       247\n",
      "           2       0.41      0.70      0.51       220\n",
      "           3       0.20      0.20      0.20       200\n",
      "           4       0.39      0.63      0.48       204\n",
      "           5       0.32      0.44      0.37       244\n",
      "           6       0.28      0.61      0.38       223\n",
      "           7       0.18      0.19      0.18       248\n",
      "           8       0.21      0.11      0.15       213\n",
      "           9       0.60      0.01      0.03       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.37      0.31      0.26      2250\n",
      "weighted avg       0.37      0.30      0.25      2250\n",
      "\n",
      "400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.06      0.11       221\n",
      "           1       0.27      0.14      0.19       247\n",
      "           2       0.41      0.70      0.51       220\n",
      "           3       0.17      0.17      0.17       200\n",
      "           4       0.37      0.62      0.46       204\n",
      "           5       0.32      0.41      0.36       244\n",
      "           6       0.28      0.61      0.38       223\n",
      "           7       0.18      0.19      0.19       248\n",
      "           8       0.21      0.11      0.15       213\n",
      "           9       0.67      0.02      0.03       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.36      0.30      0.25      2250\n",
      "weighted avg       0.36      0.30      0.25      2250\n",
      "\n",
      "500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.05      0.09       221\n",
      "           1       0.22      0.11      0.15       247\n",
      "           2       0.40      0.70      0.50       220\n",
      "           3       0.17      0.17      0.17       200\n",
      "           4       0.38      0.62      0.47       204\n",
      "           5       0.33      0.44      0.38       244\n",
      "           6       0.28      0.60      0.38       223\n",
      "           7       0.19      0.20      0.19       248\n",
      "           8       0.22      0.12      0.15       213\n",
      "           9       0.67      0.02      0.03       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.37      0.30      0.25      2250\n",
      "weighted avg       0.37      0.30      0.25      2250\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.05      0.10       221\n",
      "           1       0.26      0.13      0.18       247\n",
      "           2       0.41      0.70      0.51       220\n",
      "           3       0.19      0.19      0.19       200\n",
      "           4       0.38      0.65      0.48       204\n",
      "           5       0.31      0.40      0.35       244\n",
      "           6       0.28      0.61      0.38       223\n",
      "           7       0.20      0.21      0.21       248\n",
      "           8       0.21      0.12      0.15       213\n",
      "           9       0.60      0.01      0.03       230\n",
      "\n",
      "    accuracy                           0.30      2250\n",
      "   macro avg       0.36      0.31      0.26      2250\n",
      "weighted avg       0.36      0.30      0.26      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_est in [10,20,30,50,100,150,200,250,300,400,500,600]:\n",
    "    classifier = RandomForestRegressor(n_estimators=num_est)\n",
    "    classifier.fit(train_X, train_y)\n",
    "\n",
    "    preds_y = np.around(classifier.predict(val_X))\n",
    "    print(num_est)\n",
    "    print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.75       221\n",
      "           1       0.78      0.79      0.79       247\n",
      "           2       0.83      0.82      0.83       220\n",
      "           3       0.62      0.66      0.64       200\n",
      "           4       0.79      0.82      0.81       204\n",
      "           5       0.77      0.77      0.77       244\n",
      "           6       0.77      0.74      0.75       223\n",
      "           7       0.78      0.73      0.75       248\n",
      "           8       0.67      0.64      0.65       213\n",
      "           9       0.64      0.62      0.63       230\n",
      "\n",
      "    accuracy                           0.74      2250\n",
      "   macro avg       0.74      0.74      0.74      2250\n",
      "weighted avg       0.74      0.74      0.74      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=200)\n",
    "classifier.fit(train_X, train_y)\n",
    "\n",
    "preds_y = np.around(classifier.predict(val_X))\n",
    "print(classification_report(val_y,preds_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMAI",
   "language": "python",
   "name": "smai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
